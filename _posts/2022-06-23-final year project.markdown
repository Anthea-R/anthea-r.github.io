---
layout: post
title: "Final year project"
date: 2022-06-23 15:03:18 +0200
image: 12.jpg
tags: [Computer vision]
categories: Final-Year
---

Subgroup Analysis When Predicting the Presence of Tumour Tissue

1.	Introduction

Cancer is a global health problem and among cancers, breast cancer is the most common invasive cancer as a woman’s disease in the United States [1]. When breast cancer spreads, it typically first moves to axillary lymph nodes due to their location near the breasts. Axillary lymph nodes can be usually assessed to detect the presence of breast cancer cells. Because a delay in the manual diagnosis stays a patient at risk of the illness becoming progressively worse over time, automated diagnosis will provide an earlier signal than the manual diagnosis does. By increasing the involvement of automation in various medical operations, automated detection of lymph node metastases on histologic slides plays a potentially significant role in diagnostic and treatment decisions [2]. Treatment of cancers depends on the early diagnosis, and the treatment can be selected according to the level of malignancy [21]. Therefore, automation cancer diagnosis can lead to early identification of cancer structures and the prevention from death [22].
 For automation of cancer diagnostics and treatment, image classification is a necessary computer vision task. Support Vector Machine introduced by Vapnik [23] is a machine learning classification technique. SVM Classifiers can make a significant contribution to the medical field by providing a reliable and rapid disease diagnosis. However, in recent years, convolutional neural networks (CNNs) have become one of the prominent machine learning trends. LeNet-5 architecture [3] made up of 5 layers, very deep convolutional networks (VGG) consisted of 19 [4], and Residual Networks (ResNet) [5] can easily surpass the 100-layer barrier.  Nevertheless, difficulties that we encounter when training CNN models are a vanishing gradient problem, consisting of millions of parameters. With dense connectivity, densely connected convolutional networks (DenseNets) [6] achieve fewer parameters and high accuracy compared with VGG and ResNet. To further improve the information flow between layers, DenseNet proposes a different connectivity pattern from other CNNs. It directly connects any layer with all subsequent layers. Therefore, DenseNet has different compelling benefits: they alleviate the gradient vanishing problem, enhance feature propagation, and substantially reduce some parameters.
 Neural networks have achieved remarkable success in classification tasks in terms of average performance, but they often perform poorly on certain data groups [20]. Similarly, when a particular group is underrepresented in the training data, the model tends to perform poorly on these certain groups [30]. To avoid this, we use Group Distributionally Robust Optimisation (GDRO) in this project. The reason is that a specific hospital has low performance, and the purpose is to improve the performance. That is, it is to improve the performance of the worst case of Empirical Risk Minimisation (ERM). Distributionally Robust Optimisation (DRO) has been attracting attention in decision-making under uncertainty because of its ability to handle distribution ambiguities. In this project, through GDRO, it is possible to know from which hospital the image was acquired. Also, the subclass can be checked from which hospital each image was taken through the characteristics of the patch. In other words, it is possible to know which hospital or subgroup it is based on the patch. In robust optimisation, the decision-maker assumes no knowledge of uncertainty. Ultimately, robust optimisation minimises the worst-case cost.
 Empirical risk minimization (ERM) is one of the prevailing tools in applied machine learning. ERM was introduced to minimise the average error over the training data. That is, it shows finding a function that minimises the cost used for machine learning using limited data. However, mixup was first proposed by Zhang et al. [38] for image classification. The mixup is a method of augmenting data using convex combinations. In the case of mixup, it is a method to properly mix two data using a lambda parameter and then use it for model training. Compared with ERM, it is known to show a better effect on classification. Hence, we evaluate the mixup on the CAMELYON17-WILDS dataset. 
 This project aims to develop a machine learning model that generalises domains in the context of medical data. To improve automated detection and classification of breast cancer metastases in lymph nodes, the ‘Cancer MEtastages in Lymph nOdes challeNge’ (CAMELYON17) was organised in 2017. The given dataset for CAMELYON17 [40] contains images from five medical centres in the Netherlands. WILDS dataset is a recent benchmark dataset based on CAMELYON17 for tissue patches cumulated from the five individual hospitals. The CAMELYON17-WILDS dataset can be separated as train, validation, id validation, and test data. In a total of 5 medical centres, the first, second, and third hospitals are in the training dataset, the fourth hospital is in the validation dataset, and the fifth hospital is in the test dataset. 
 This report proposes DenseNet architecture to identify breast cancer image patches obtained from digital pathology scans. This report also suggests a subgroup architecture, which shows where the patches came from among the five hospitals by subgrouping each hospital as a part of the entire hospital. We present a highly precise automated framework that can be applied for cancer detection and classification. The process of subgrouping each hospital from a large group of hospitals presents a technique to improve the performance of the worst group. Also, we use the mixup algorithm as a data augmentation technique to increase the model’s performance while preventing overfitting. 
 The main contributions of this paper are presented as follows. Section 2 presents ethical and professional considerations for this project. Since DenseNet is a model based on CNN, the background for CNN is be described in Section 3. Related work and recent research progress on image classification using CNN and DenseNet, worst-case performance improvements using GDRO, and performance enhancement using mixup are introduced in Section 4. Section 5 mainly describes our algorithm based on DenseNet, GDRO, and mixup. Next, in Section 6, we achieve results for image and subclass classification, and performance enhancement.  Section 7 interprets our experimental findings. Finally, the conclusion of this project is in Section 8.


